#!/usr/bin/python3
# Copyright Douglas Bagnall <douglas@halo.gen.nz> GPLv3
import sys
import re
import argparse
import unicodedata
from collections import Counter

def possible_n_grams(n, state='v'):
    """Estimate the number of possible n-grams, very roughly."""
    # let's assume there are two states, vowel and consonant.
    #vowels = 10     # a e i o u ā ē ī ō ū
    #consonants = 10 # h k m n ng p r t w wh
    if n <= 0:
        return 1

    total = 0
    if state == 'v':
        total += 10 * possible_n_grams(n - 1, 'c')
    total += 10 * possible_n_grams(n - 1, 'v')
    return total

def generate_n_grams(n, prefix='', macrons=False):
    """Estimate the number of possible n-grams, very roughly."""
    # let's assume there are two states, vowel and consonant.
    if n <= 0:
        return [prefix]

    chars = 'aeiou'
    if macrons:
        chars += 'āēīōū'

    if prefix == '' or prefix[-1] in 'aeiouāēīōū':
        chars += 'fhkmnŋprtw'

    ngrams = []
    for c in chars:
        ngrams.extend(generate_n_grams(n - 1, prefix + c))
    return ngrams

def remove_english(text):
    words = text.split()
    good_words = []
    #has_bad_letter = re.compile('bcdgjlqsvxyz').search
    has_bad_letter = re.compile('[^aeiouāēīōūfhkmnŋprtw]').search
    has_bad_cluster = re.compile('[fhkmnŋprtw][fhkmnŋprtw]').search
    for word in words:
        if has_bad_letter(word) or has_bad_cluster(word):
            continue
        good_words.append(word)
    return ' '.join(good_words)

DIPHTHONGS = {
    'ae': 'æ',
    'ai': 'ȧ',
    'ao': 'å',
    'au': 'ä',
    'oi': 'ȯ',
    'oe': 'œ',
    'ou': 'ö'
}


def normalise_text(text, diphthongs, expand_macrons):
    text = unicodedata.normalize('NFC', text)
    text = text.lower()
    text = re.sub(r'[^\wāēōūī]+', ' ', text)
    text = re.sub(r'ng', 'ŋ', text)
    text = re.sub(r'wh', 'f', text)
    text = remove_english(text)
    if expand_macrons:
        text = demacronise(text)
    if diphthongs:
        for k, v in DIPHTHONGS.items():
            text = re.sub(k, v, text)
    return text


def denormalise_text(text):
    text = re.sub(r'ŋ', 'ng', text)
    text = re.sub(r'f', 'wh', text)
    for k, v in DIPHTHONGS.items():
        text = re.sub(v, k, text)
    return text


def demacronise(text):
    return text.replace('ā', 'aa').replace('ē', 'ee')\
                                  .replace('ī', 'ii')\
                                  .replace('ō', 'oo').replace('ū', 'uu')


def count_ngrams(text, n):
    texts = [text[i:] for i in range(n)]
    ngrams = Counter(''.join(x) for x in zip(*texts) if ' ' not in x)
    return ngrams


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('textfile', help="read text from this file")
    parser.add_argument('-d', '--diphthongs', action='store_true',
                        help="count diphthongs as single units")
    parser.add_argument('-m', '--expand-macrons', action='store_true',
                        help="convert macronised vowels into double vowels")
    parser.add_argument('-n', '--n-gram-size', type=int, default=2,
                        help="use n-grams of this size (default 2)")
    args = parser.parse_args()

    fn = args.textfile
    f = open(fn)
    raw = f.read()
    f.close()

    text = normalise_text(raw, args.diphthongs, args.expand_macrons)

    ngrams = count_ngrams(text, args.n_gram_size)
    for bigram, n in ngrams.most_common():
        print("%5d  %s   %s" % (n, bigram, denormalise_text(bigram)))
    print("Total %d-grams: %s" % (args.n_gram_size, len(ngrams)))
    print()

    possible = generate_n_grams(args.n_gram_size)

    common = {k for k, v in ngrams.most_common() if v > 3}
    missing = set(possible) - set(ngrams)
    print ("These %d-grams do not occur in %s" %
           (args.n_gram_size, fn))
    for x in sorted(missing):
        print(x, denormalise_text(x))

main()
