#!/usr/bin/python3
# Copyright Douglas Bagnall <douglas@halo.gen.nz> GPLv3

import argparse
from collections import Counter

from reo import load_text, denormalise_text, generate_n_grams


def count_ngrams(text, n):
    texts = [text[i:] for i in range(n)]
    ngrams = Counter(''.join(x) for x in zip(*texts) if ' ' not in x)
    return ngrams


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('textfiles', nargs='+',
                        help="read text from these file")
    parser.add_argument('-d', '--diphthongs', action='store_true',
                        help="count diphthongs as single units")
    parser.add_argument('-m', '--expand-macrons', action='store_true',
                        help="convert macronised vowels into double vowels")
    parser.add_argument('-n', '--n-gram-size', type=int, default=2,
                        help="use n-grams of this size (default 2)")
    parser.add_argument('-b', '--word-boundaries', action='store_true',
                        help="mark the start and end of words")
    args = parser.parse_args()

    text = load_text(args.textfiles, args.diphthongs,
                     not args.expand_macrons)

    if args.word_boundaries:
        words = text.split()
        text = "«%s»" % ("» «".join(words))

    ngrams = count_ngrams(text, args.n_gram_size)
    for bigram, n in ngrams.most_common():
        print("%5d  %s   %s" % (n, bigram, denormalise_text(bigram)))
    print("Total %d-grams: %s" % (args.n_gram_size, len(ngrams)))
    print()

    possible = generate_n_grams(args.n_gram_size, '', args.diphthongs,
                                not args.expand_macrons)
    if args.word_boundaries:
        short = generate_n_grams(args.n_gram_size - 1, '', args.diphthongs,
                                 not args.expand_macrons)
        possible += ["«" + x for x in short]
        possible += [x + "»" for x in short if x[-1] in set('aeiouāēīōū')]

    missing = set(possible) - set(ngrams)
    print ("These %d-grams do not occur in %s" %
           (args.n_gram_size, ' or '.join(args.textfiles)))
    for x in sorted(missing):
        print("       %s   %s" % (x, denormalise_text(x)))

main()
